{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documents Welcome to the fcast documentation page! View the project on GitHub. This project is early in its life and is still under development. As such, the classes, their methods and attributes, and the functions available in this library are focused on forecasting flood events and their impact on transportation infrastructure. This is not a comprehensive API of the output of the National Water Model. If there is interest in making fcast into a more comprehensive API for the NWM, please see Contributing for guidance on how to participate in this project.","title":"Home"},{"location":"#documents","text":"Welcome to the fcast documentation page! View the project on GitHub. This project is early in its life and is still under development. As such, the classes, their methods and attributes, and the functions available in this library are focused on forecasting flood events and their impact on transportation infrastructure. This is not a comprehensive API of the output of the National Water Model. If there is interest in making fcast into a more comprehensive API for the NWM, please see Contributing for guidance on how to participate in this project.","title":"Documents"},{"location":"Assim/","text":"Assim According to NOAA on the NWM : The Standard Analysis and Assimilation configuration cycles hourly and produces a real-time analysis of the current streamflow and other surface and near-surface hydrologic states across the contiguous United States (CONUS). This configuration is internally cycling, with each subsequent Standard Analysis starting from the previous hour\u2019s run. The exception is the 19Z Standard Analysis cycle which ingests initial conditions from the Extended Analysis below. The Standard Analysis also produces restart files each hour which are used to initialize the short-, medium-, and long-range forecast simulations. Meteorological forcing data are drawn from the MRMS Gauge-adjusted and Radar-only observed precipitation products along with short-range RAP and HRRR, while stream-gauge observations are assimilated from the USGS. Usage: Assim(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, offset=0, NWMtype='assim') A representation of an Analysis Assimilation NWM netcdf file on GCS This is used to get the initial time and streamflow for a forecast being made Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified. hr (int, optional) : The hour of the analysis assim of interest (e.g. 0, 1, or 2). Defaults to 0 Attributes / Methods: assim_flow The streamflow at the analysis assimilation time assim_time The analysis assimilation time filepath The filepath of the netcdf on GCS being utilized nfiles The number of available files for this output (NWM v2 has 3 for analysis_assim) offset The hour of the analysis assim of interest (e.g. 0, 1, or 2). Defaults to 0","title":"Assim"},{"location":"Assim/#assim","text":"According to NOAA on the NWM : The Standard Analysis and Assimilation configuration cycles hourly and produces a real-time analysis of the current streamflow and other surface and near-surface hydrologic states across the contiguous United States (CONUS). This configuration is internally cycling, with each subsequent Standard Analysis starting from the previous hour\u2019s run. The exception is the 19Z Standard Analysis cycle which ingests initial conditions from the Extended Analysis below. The Standard Analysis also produces restart files each hour which are used to initialize the short-, medium-, and long-range forecast simulations. Meteorological forcing data are drawn from the MRMS Gauge-adjusted and Radar-only observed precipitation products along with short-range RAP and HRRR, while stream-gauge observations are assimilated from the USGS. Usage: Assim(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, offset=0, NWMtype='assim') A representation of an Analysis Assimilation NWM netcdf file on GCS This is used to get the initial time and streamflow for a forecast being made Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified. hr (int, optional) : The hour of the analysis assim of interest (e.g. 0, 1, or 2). Defaults to 0","title":"Assim"},{"location":"Assim/#attributes-methods","text":"","title":"Attributes / Methods:"},{"location":"Assim/#assim_flow","text":"The streamflow at the analysis assimilation time","title":"assim_flow"},{"location":"Assim/#assim_time","text":"The analysis assimilation time","title":"assim_time"},{"location":"Assim/#filepath","text":"The filepath of the netcdf on GCS being utilized","title":"filepath"},{"location":"Assim/#nfiles","text":"The number of available files for this output (NWM v2 has 3 for analysis_assim)","title":"nfiles"},{"location":"Assim/#offset","text":"The hour of the analysis assim of interest (e.g. 0, 1, or 2). Defaults to 0","title":"offset"},{"location":"GageUSGS/","text":"GageUSGS GageUSGS is a class object used for webscraping metadata, current information, and rating curves from USGS stream flow gages. At the moment, tidal and estuary gages are not supported. This file only works on python version 3.6 or newer. GageUSGS(self, gage: str, get_rc: bool = True) USGS stream gage class containing data scraped from USGS websites. The class currently supports scraping of stream gage metadata (i.e. vertical datum, lat/lon, etc.), currently available data at a gage, as well as rating curves and their metadata. Parameters: gage (str) : A string representing a USGS gage id (e.g. '01400000'). get_rc (bool, optional) : Get the rating curve for the USGS gage. Defaults to True. Attributes / Methods: available_data The data available from the metadata url drainage_area_sqmi Drainage area upstream of the gage in sq miles feet_above_vertical_datum Feet above the vertical datum, for stage to elevation conversions gage Gage id string horizontal_datum Horizontal Datum of the gage HUC8 HUC8 that the gage is within lat Latitude of the gage lon Longitude of the gage metadata Dictionary of general gage metadata metadata_url Url that the gage metadata is gathered from rating_curve USGS Rating curve at gage location rating_curve_metadata USGS Rating curve metadata at gage location vertical_datum Vertical datum of the gage","title":"GageUSGS"},{"location":"GageUSGS/#gageusgs","text":"GageUSGS is a class object used for webscraping metadata, current information, and rating curves from USGS stream flow gages. At the moment, tidal and estuary gages are not supported. This file only works on python version 3.6 or newer. GageUSGS(self, gage: str, get_rc: bool = True) USGS stream gage class containing data scraped from USGS websites. The class currently supports scraping of stream gage metadata (i.e. vertical datum, lat/lon, etc.), currently available data at a gage, as well as rating curves and their metadata. Parameters: gage (str) : A string representing a USGS gage id (e.g. '01400000'). get_rc (bool, optional) : Get the rating curve for the USGS gage. Defaults to True.","title":"GageUSGS"},{"location":"GageUSGS/#attributes-methods","text":"","title":"Attributes / Methods:"},{"location":"GageUSGS/#available_data","text":"The data available from the metadata url","title":"available_data"},{"location":"GageUSGS/#drainage_area_sqmi","text":"Drainage area upstream of the gage in sq miles","title":"drainage_area_sqmi"},{"location":"GageUSGS/#feet_above_vertical_datum","text":"Feet above the vertical datum, for stage to elevation conversions","title":"feet_above_vertical_datum"},{"location":"GageUSGS/#gage","text":"Gage id string","title":"gage"},{"location":"GageUSGS/#horizontal_datum","text":"Horizontal Datum of the gage","title":"horizontal_datum"},{"location":"GageUSGS/#huc8","text":"HUC8 that the gage is within","title":"HUC8"},{"location":"GageUSGS/#lat","text":"Latitude of the gage","title":"lat"},{"location":"GageUSGS/#lon","text":"Longitude of the gage","title":"lon"},{"location":"GageUSGS/#metadata","text":"Dictionary of general gage metadata","title":"metadata"},{"location":"GageUSGS/#metadata_url","text":"Url that the gage metadata is gathered from","title":"metadata_url"},{"location":"GageUSGS/#rating_curve","text":"USGS Rating curve at gage location","title":"rating_curve"},{"location":"GageUSGS/#rating_curve_metadata","text":"USGS Rating curve metadata at gage location","title":"rating_curve_metadata"},{"location":"GageUSGS/#vertical_datum","text":"Vertical datum of the gage","title":"vertical_datum"},{"location":"MediumRange/","text":"MediumRange According to NOAA on the NWM: The Medium Range Forecast configuration is executed four times per day, forced with GFS model output. Member 1 extends out to 10 days while members 2-7 extend out to 8.5 days. This configuration produces 3-hourly deterministic output and is initialized with the restart file from the Analysis and Assimilation configuration. Usage: MediumRange(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, members: list = [1, 2, 3, 4, 5, 6, 7], NWMtype='medium') A representation of a Medium Range forecast made using NWM netcdf files on GCS Pulls the relevant files from GCS to make an 8.5 day streamflow forecast beginning at a specified date and start time (UTC), with data points in 3 hour steps. Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified. members (list) : The members you want the medium range forecast for. Defaults to [1, 2, 3, 4, 5, 6, 7] Attributes / Methods: filepaths A list of lists, each containing the filepaths used for each member forecast_hours A list of forecast hours. For MediumRange this is hours 3-204 in steps of 3 mem_dsets A list of stacked xarray datasets, each representing a member members The members that a MediumRange forecast will be created for nfiles The total number of files used to build the forecast get_streamflow MediumRange.get_streamflow(self, assim_time: str, assim_flow: float) -> pandas.core.frame.DataFrame Get the forecasted streamflow for all selected members in one pandas dataframe, given an assim_time and assim_flow produced using the Assim class.","title":"MediumRange"},{"location":"MediumRange/#mediumrange","text":"According to NOAA on the NWM: The Medium Range Forecast configuration is executed four times per day, forced with GFS model output. Member 1 extends out to 10 days while members 2-7 extend out to 8.5 days. This configuration produces 3-hourly deterministic output and is initialized with the restart file from the Analysis and Assimilation configuration. Usage: MediumRange(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, members: list = [1, 2, 3, 4, 5, 6, 7], NWMtype='medium') A representation of a Medium Range forecast made using NWM netcdf files on GCS Pulls the relevant files from GCS to make an 8.5 day streamflow forecast beginning at a specified date and start time (UTC), with data points in 3 hour steps. Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified. members (list) : The members you want the medium range forecast for. Defaults to [1, 2, 3, 4, 5, 6, 7]","title":"MediumRange"},{"location":"MediumRange/#attributes-methods","text":"","title":"Attributes / Methods:"},{"location":"MediumRange/#filepaths","text":"A list of lists, each containing the filepaths used for each member","title":"filepaths"},{"location":"MediumRange/#forecast_hours","text":"A list of forecast hours. For MediumRange this is hours 3-204 in steps of 3","title":"forecast_hours"},{"location":"MediumRange/#mem_dsets","text":"A list of stacked xarray datasets, each representing a member","title":"mem_dsets"},{"location":"MediumRange/#members","text":"The members that a MediumRange forecast will be created for","title":"members"},{"location":"MediumRange/#nfiles","text":"The total number of files used to build the forecast","title":"nfiles"},{"location":"MediumRange/#get_streamflow","text":"MediumRange.get_streamflow(self, assim_time: str, assim_flow: float) -> pandas.core.frame.DataFrame Get the forecasted streamflow for all selected members in one pandas dataframe, given an assim_time and assim_flow produced using the Assim class.","title":"get_streamflow"},{"location":"ShortRange/","text":"ShortRange According to NOAA on the NWM: Forced with meteorological data from the HRRR and RAP models, the Short Range Forecast configuration cycles hourly and produces hourly deterministic forecasts of streamflow and hydrologic states out to 18 hours. The model is initialized with a restart file from the Analysis and Assimilation configuration and does not cycle on its own states. Usage: ShortRange(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, NWMtype='short') A representation of a Short Range forecast made using NWM netcdf files on GCS Pulls the relevant files from Google Cloud Storage to make an 18 hour streamflow forecast beginning at a specified date and start time (UTC). Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information available here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified. Attributes / Methods: ds The stacked xarray dataset representing the forecast filepaths A list of the filepaths used to build the forecast forecast_hours A list of forecast hours. For ShortRange this is hours 1-18 nfiles The number of files that make up the forecast get_streamflow ShortRange.get_streamflow(self, assim_time: str, assim_flow: float) -> pandas.core.frame.DataFrame Get the streamflow forecast in a pandas dataframe, given an assim_time and assim_flow produced using the Assim class","title":"ShortRange"},{"location":"ShortRange/#shortrange","text":"According to NOAA on the NWM: Forced with meteorological data from the HRRR and RAP models, the Short Range Forecast configuration cycles hourly and produces hourly deterministic forecasts of streamflow and hydrologic states out to 18 hours. The model is initialized with a restart file from the Analysis and Assimilation configuration and does not cycle on its own states. Usage: ShortRange(self, fs: gcsfs.core.GCSFileSystem, comid: int, date: str, start_hr: int, NWMtype='short') A representation of a Short Range forecast made using NWM netcdf files on GCS Pulls the relevant files from Google Cloud Storage to make an 18 hour streamflow forecast beginning at a specified date and start time (UTC). Parameters: fs (gcsfs.core.GCSFileSystem) : The mounted NWM Google Cloud Storage Bucket using gcsfs. This is created like so: fs = gcsfs.GCSFileSystem(project='national-water-model') comid (int) : The ComID that corresponds to the stream segment of interest. The ComID is a common identifier (unique) that allows a user of the NHDPlusV21 to access the same stream segements across the entire NHDPlus anywhere in the country. More information available here. date (str) : The date of the model output being used. (e.g. '20190802' for Aug 2, 2019) start_hr (int) : The starting time (UTC) on for the date specified.","title":"ShortRange"},{"location":"ShortRange/#attributes-methods","text":"","title":"Attributes / Methods:"},{"location":"ShortRange/#ds","text":"The stacked xarray dataset representing the forecast","title":"ds"},{"location":"ShortRange/#filepaths","text":"A list of the filepaths used to build the forecast","title":"filepaths"},{"location":"ShortRange/#forecast_hours","text":"A list of forecast hours. For ShortRange this is hours 1-18","title":"forecast_hours"},{"location":"ShortRange/#nfiles","text":"The number of files that make up the forecast","title":"nfiles"},{"location":"ShortRange/#get_streamflow","text":"ShortRange.get_streamflow(self, assim_time: str, assim_flow: float) -> pandas.core.frame.DataFrame Get the streamflow forecast in a pandas dataframe, given an assim_time and assim_flow produced using the Assim class","title":"get_streamflow"},{"location":"StreamSegmentNHD/","text":"StreamSegmentNHD StreamSegmentNHD is a class object that represents a stream segment in the NHDPlusV2.1. It is built for easy access to a single stream segment represented by a ComID without overburdening memory. It is meant for the NHDPlusV21_National_Seamless_Flattened_Lower48.gdb. It also requires a ComID dictionary used as a map, which can be found at s3://nwm-datasets/Data/Vector/NHDPlusV21_CONUS_seamless/comidDict_NHDPlusV21.json or can be made using fiona like so: gdb = 'NHDPlusV21_National_Seamless_Flattened_Lower48.gdb' src = fiona.open(gdb, layer='NHDFlowline_Network') comidDict = {src[f]['properties']['COMID']: k for k in src.keys()} StreamSegmentNHD(self, comid: int, comidDict: dict, src: fiona.collection, warning: bool = True) A representation of one individual NHDPlusV2.1 ComID stream segment. For detailed information on the dataset, download the Release Notes from here All property docstrings have been pulled from these release notes. Parameters: comid (int) : The comID that corresponds to the stream segment of interest. comidDict (dict) : The dictionary used to map the ComIDs to the feature index in the gdb. Generally loaded into memory using json.load(filepath) src (fiona.collection) : The open fiona collection representing the gdb and the 'NHDFlowline_Network' layer. warning (bool, optional) : Defaults to true. Raises a warning to ensure the comidDict NHDPlus version matches that of the gdb. Attributes / Methods: annual_mean_flow_QA Mean Annual Flow from runoff (cfs) annual_mean_flow_QC Mean Annual Flow with Reference Gage Regression applied to QB (cfs). Best EROM estimate of \"natural\" mean flow. annual_mean_flow_QE Mean Annual Flow from gage adjustment (cfs). Best EROM estimate of actual mean flow. annual_mean_vel_QA Mean Annual Velocity for QA (fps) annual_mean_vel_QC Mean Annual Velocity for QC (fps). Best EROM estimate of \"natural\" mean velocity. annual_mean_vel_QE Mean Annual Velocity from gage adjustment (fps). Best EROM estimate of actual mean velocity. attrs An OrderedDict of all attributes for the stream segment comid Common identifier of the NHD feature comidDict Dictionary containing the ComID -> feature index map crs_proj4 The crs of the dataset as a proj4 string crs_wkt The crs of the dataset as wkt current_month_QV 'QA': 'Mean Annual Flow from runoff (cfs)', 'VA': 'Mean Annual Velocity for QA (fps)', 'QC': 'Mean Annual Flow with Reference Gage Regression applied to QB (cfs). Best EROM estimate of \"natural\" mean flow.', 'VC': 'Mean Annual Velocity for QC (fps). Best EROM estimate of \"natural\" mean velocity.', 'QE': 'Mean Annual Flow from gage adjustment (cfs). Best EROM estimate of actual mean flow.', 'VE': 'Mean Annual Velocity from gage adjustment (fps). Best EROM estimate of actual mean velocity. feat_currency_date Feature Currency Date from_node_id Unique identifier for the point at the top of the NHDFlowline feature geometry Shapely representation of the line segment GNIS_id Geographic Names Information System ID for the value in GNIS_Name GNIS_name Feature Name from the Geographic Names Information System length_km Feature length in kilometers max_elev_raw Maximum elevation (unsmoothed) in centimeters max_elev_smoothed Maximum elevation (smoothed) in centimeters min_elev_raw Minimum elevation (unsmoothed) in centimeters min_elev_smoothed Minimum elevation (smoothed) in centimeters QV_meta Metadata describing the results of current_month_QV reach_code Reach Code assigned to feature resolution NHD database resolution (i.e. 'high', 'medium' or 'local') src The opened fiona collection of the gdb and the 'NHDFlowline_Network' layer stream_order Modified Strahler Stream Order tidal Is Flowline Tidal? 1=yes, 0=no to_node_id Unique identifier for the point at the end of the NHDFlowline feature tot_drainage_area_sqkm Total upstream catchment area from downstream end of flowline. WB_area_comid ComID of the NHD polygonal water feature through which a NHD \"Artificial Path\" flowline flows","title":"StreamSegmentNHD"},{"location":"StreamSegmentNHD/#streamsegmentnhd","text":"StreamSegmentNHD is a class object that represents a stream segment in the NHDPlusV2.1. It is built for easy access to a single stream segment represented by a ComID without overburdening memory. It is meant for the NHDPlusV21_National_Seamless_Flattened_Lower48.gdb. It also requires a ComID dictionary used as a map, which can be found at s3://nwm-datasets/Data/Vector/NHDPlusV21_CONUS_seamless/comidDict_NHDPlusV21.json or can be made using fiona like so: gdb = 'NHDPlusV21_National_Seamless_Flattened_Lower48.gdb' src = fiona.open(gdb, layer='NHDFlowline_Network') comidDict = {src[f]['properties']['COMID']: k for k in src.keys()} StreamSegmentNHD(self, comid: int, comidDict: dict, src: fiona.collection, warning: bool = True) A representation of one individual NHDPlusV2.1 ComID stream segment. For detailed information on the dataset, download the Release Notes from here All property docstrings have been pulled from these release notes. Parameters: comid (int) : The comID that corresponds to the stream segment of interest. comidDict (dict) : The dictionary used to map the ComIDs to the feature index in the gdb. Generally loaded into memory using json.load(filepath) src (fiona.collection) : The open fiona collection representing the gdb and the 'NHDFlowline_Network' layer. warning (bool, optional) : Defaults to true. Raises a warning to ensure the comidDict NHDPlus version matches that of the gdb.","title":"StreamSegmentNHD"},{"location":"StreamSegmentNHD/#attributes-methods","text":"","title":"Attributes / Methods:"},{"location":"StreamSegmentNHD/#annual_mean_flow_qa","text":"Mean Annual Flow from runoff (cfs)","title":"annual_mean_flow_QA"},{"location":"StreamSegmentNHD/#annual_mean_flow_qc","text":"Mean Annual Flow with Reference Gage Regression applied to QB (cfs). Best EROM estimate of \"natural\" mean flow.","title":"annual_mean_flow_QC"},{"location":"StreamSegmentNHD/#annual_mean_flow_qe","text":"Mean Annual Flow from gage adjustment (cfs). Best EROM estimate of actual mean flow.","title":"annual_mean_flow_QE"},{"location":"StreamSegmentNHD/#annual_mean_vel_qa","text":"Mean Annual Velocity for QA (fps)","title":"annual_mean_vel_QA"},{"location":"StreamSegmentNHD/#annual_mean_vel_qc","text":"Mean Annual Velocity for QC (fps). Best EROM estimate of \"natural\" mean velocity.","title":"annual_mean_vel_QC"},{"location":"StreamSegmentNHD/#annual_mean_vel_qe","text":"Mean Annual Velocity from gage adjustment (fps). Best EROM estimate of actual mean velocity.","title":"annual_mean_vel_QE"},{"location":"StreamSegmentNHD/#attrs","text":"An OrderedDict of all attributes for the stream segment","title":"attrs"},{"location":"StreamSegmentNHD/#comid","text":"Common identifier of the NHD feature","title":"comid"},{"location":"StreamSegmentNHD/#comiddict","text":"Dictionary containing the ComID -> feature index map","title":"comidDict"},{"location":"StreamSegmentNHD/#crs_proj4","text":"The crs of the dataset as a proj4 string","title":"crs_proj4"},{"location":"StreamSegmentNHD/#crs_wkt","text":"The crs of the dataset as wkt","title":"crs_wkt"},{"location":"StreamSegmentNHD/#current_month_qv","text":"'QA': 'Mean Annual Flow from runoff (cfs)', 'VA': 'Mean Annual Velocity for QA (fps)', 'QC': 'Mean Annual Flow with Reference Gage Regression applied to QB (cfs). Best EROM estimate of \"natural\" mean flow.', 'VC': 'Mean Annual Velocity for QC (fps). Best EROM estimate of \"natural\" mean velocity.', 'QE': 'Mean Annual Flow from gage adjustment (cfs). Best EROM estimate of actual mean flow.', 'VE': 'Mean Annual Velocity from gage adjustment (fps). Best EROM estimate of actual mean velocity.","title":"current_month_QV"},{"location":"StreamSegmentNHD/#feat_currency_date","text":"Feature Currency Date","title":"feat_currency_date"},{"location":"StreamSegmentNHD/#from_node_id","text":"Unique identifier for the point at the top of the NHDFlowline feature","title":"from_node_id"},{"location":"StreamSegmentNHD/#geometry","text":"Shapely representation of the line segment","title":"geometry"},{"location":"StreamSegmentNHD/#gnis_id","text":"Geographic Names Information System ID for the value in GNIS_Name","title":"GNIS_id"},{"location":"StreamSegmentNHD/#gnis_name","text":"Feature Name from the Geographic Names Information System","title":"GNIS_name"},{"location":"StreamSegmentNHD/#length_km","text":"Feature length in kilometers","title":"length_km"},{"location":"StreamSegmentNHD/#max_elev_raw","text":"Maximum elevation (unsmoothed) in centimeters","title":"max_elev_raw"},{"location":"StreamSegmentNHD/#max_elev_smoothed","text":"Maximum elevation (smoothed) in centimeters","title":"max_elev_smoothed"},{"location":"StreamSegmentNHD/#min_elev_raw","text":"Minimum elevation (unsmoothed) in centimeters","title":"min_elev_raw"},{"location":"StreamSegmentNHD/#min_elev_smoothed","text":"Minimum elevation (smoothed) in centimeters","title":"min_elev_smoothed"},{"location":"StreamSegmentNHD/#qv_meta","text":"Metadata describing the results of current_month_QV","title":"QV_meta"},{"location":"StreamSegmentNHD/#reach_code","text":"Reach Code assigned to feature","title":"reach_code"},{"location":"StreamSegmentNHD/#resolution","text":"NHD database resolution (i.e. 'high', 'medium' or 'local')","title":"resolution"},{"location":"StreamSegmentNHD/#src","text":"The opened fiona collection of the gdb and the 'NHDFlowline_Network' layer","title":"src"},{"location":"StreamSegmentNHD/#stream_order","text":"Modified Strahler Stream Order","title":"stream_order"},{"location":"StreamSegmentNHD/#tidal","text":"Is Flowline Tidal? 1=yes, 0=no","title":"tidal"},{"location":"StreamSegmentNHD/#to_node_id","text":"Unique identifier for the point at the end of the NHDFlowline feature","title":"to_node_id"},{"location":"StreamSegmentNHD/#tot_drainage_area_sqkm","text":"Total upstream catchment area from downstream end of flowline.","title":"tot_drainage_area_sqkm"},{"location":"StreamSegmentNHD/#wb_area_comid","text":"ComID of the NHD polygonal water feature through which a NHD \"Artificial Path\" flowline flows","title":"WB_area_comid"},{"location":"about/","text":"Overview fcast is a collection of python tools used for leveraging National Water Model and other data products to forecast flood events and their potential impacts on transportation infrastructure. Click here for more information on the floodcast project ( fcast ). The following datasets are used: The NHDPlus V2.1 dataset In particular, the NHDPlusV21_National_Seamless_Flattened_Lower48.gdb is utilized. Staged Elevation from The National Map . FTP USGS National Transportation Dataset (NTD) The National Water Model (NWM) GCS AWS","title":"About"},{"location":"about/#overview","text":"fcast is a collection of python tools used for leveraging National Water Model and other data products to forecast flood events and their potential impacts on transportation infrastructure. Click here for more information on the floodcast project ( fcast ). The following datasets are used: The NHDPlus V2.1 dataset In particular, the NHDPlusV21_National_Seamless_Flattened_Lower48.gdb is utilized. Staged Elevation from The National Map . FTP USGS National Transportation Dataset (NTD) The National Water Model (NWM) GCS AWS","title":"Overview"},{"location":"changelog/","text":"Changelog To-do: Incorporate transit","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#to-do","text":"Incorporate transit","title":"To-do:"},{"location":"contributing/","text":"Contributing If you would like to contribute code in the form of bug fixes, new features or other patches this page gives you more info on how to do so. Git Branching Model Dewberry follows the standard practice of using the master branch as the main integration branch. Git Commit Messages We follow the 'imperative present tense' style for commit messages. (e.g. \"Add function to plot MediumRange forecasts\") Issue Tracking If you find a bug, have a question, etc., and would like to report it please go to the fcast Github page and create an issue. Pull Requests If you'd like to submit a code contribution please fork fcast and send a pull request against the master branch. Like any other open source project, we might ask you to go through some iterations of discussion and refinement before merging. Editing these Docs Contributions to these docs are welcome as well. To build them on your own machine, ensure that MkDocs is installed.","title":"Contributing"},{"location":"contributing/#contributing","text":"If you would like to contribute code in the form of bug fixes, new features or other patches this page gives you more info on how to do so.","title":"Contributing"},{"location":"contributing/#git-branching-model","text":"Dewberry follows the standard practice of using the master branch as the main integration branch.","title":"Git Branching Model"},{"location":"contributing/#git-commit-messages","text":"We follow the 'imperative present tense' style for commit messages. (e.g. \"Add function to plot MediumRange forecasts\")","title":"Git Commit Messages"},{"location":"contributing/#issue-tracking","text":"If you find a bug, have a question, etc., and would like to report it please go to the fcast Github page and create an issue.","title":"Issue Tracking"},{"location":"contributing/#pull-requests","text":"If you'd like to submit a code contribution please fork fcast and send a pull request against the master branch. Like any other open source project, we might ask you to go through some iterations of discussion and refinement before merging.","title":"Pull Requests"},{"location":"contributing/#editing-these-docs","text":"Contributions to these docs are welcome as well. To build them on your own machine, ensure that MkDocs is installed.","title":"Editing these Docs"},{"location":"get_USGS_rc/","text":"get_USGS_rc get_USGS_rc(comid: int) Given a comid, get the rating curve for the matching USGS Gages. currently only works with access to s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json .","title":"get_USGS_rc"},{"location":"get_USGS_rc/#get_usgs_rc","text":"get_USGS_rc(comid: int) Given a comid, get the rating curve for the matching USGS Gages. currently only works with access to s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json .","title":"get_USGS_rc"},{"location":"get_USGS_stations/","text":"get_USGS_stations get_USGS_stations(comid: int, s3path='s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json') -> list Given a comid, go find the corresponding USGS gage ids. Currently only works with access to s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json . This functions source code can be easily refactored to accept a comidDict, which can be created by doing the following: gdb = 'NHDPlusV21_National_Seamless_Flattened_Lower48.gdb' src = fiona.open(gdb, layer='NHDFlowline_Network') comidDict = {src[f]['properties']['COMID']: k for k in src.keys()}","title":"get_USGS_stations"},{"location":"get_USGS_stations/#get_usgs_stations","text":"get_USGS_stations(comid: int, s3path='s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json') -> list Given a comid, go find the corresponding USGS gage ids. Currently only works with access to s3://nwm-datasets/Data/Vector/USGS_NHDPlusv2/STATID_COMID_dict.json . This functions source code can be easily refactored to accept a comidDict, which can be created by doing the following: gdb = 'NHDPlusV21_National_Seamless_Flattened_Lower48.gdb' src = fiona.open(gdb, layer='NHDFlowline_Network') comidDict = {src[f]['properties']['COMID']: k for k in src.keys()}","title":"get_USGS_stations"},{"location":"new_plot/","text":"new_plot new_plot(figsize: tuple = (20, 6), fontsize: int = 18, xlabel: str = 'Discharge (cms)', ylabel: str = 'Stage') -> plt.subplots Generic plot setup, optimized for viewing in a Jupyter Notebook. Parameters figsize : recommeded 20,6 for notebooks fontsize : label fontsize xlabel : be careful, best to make a test to verify units are consistent ylabel : be careful, best to make a test to verify units are consistent","title":"new_plot"},{"location":"new_plot/#new_plot","text":"new_plot(figsize: tuple = (20, 6), fontsize: int = 18, xlabel: str = 'Discharge (cms)', ylabel: str = 'Stage') -> plt.subplots Generic plot setup, optimized for viewing in a Jupyter Notebook. Parameters figsize : recommeded 20,6 for notebooks fontsize : label fontsize xlabel : be careful, best to make a test to verify units are consistent ylabel : be careful, best to make a test to verify units are consistent","title":"new_plot"},{"location":"plotMediumRange/","text":"plotMediumRange plotMediumRange(df: pandas.core.frame.DataFrame, comid: int, flow: bool = True) Function for plotting medium range forecasts. Set flow = False if plotting stage. df is the output of ShortRange.get_streamflow() .","title":"plotMediumRange"},{"location":"plotMediumRange/#plotmediumrange","text":"plotMediumRange(df: pandas.core.frame.DataFrame, comid: int, flow: bool = True) Function for plotting medium range forecasts. Set flow = False if plotting stage. df is the output of ShortRange.get_streamflow() .","title":"plotMediumRange"},{"location":"plotShortRange/","text":"plotShortRange plotShortRange(df: pandas.core.frame.DataFrame, comid: int, flow: bool = True) Function for plotting short range forecasts. Set flow = False if plotting stage. df is the output of ShortRange.get_streamflow() .","title":"plotShortRange"},{"location":"plotShortRange/#plotshortrange","text":"plotShortRange(df: pandas.core.frame.DataFrame, comid: int, flow: bool = True) Function for plotting short range forecasts. Set flow = False if plotting stage. df is the output of ShortRange.get_streamflow() .","title":"plotShortRange"},{"location":"quickstart/","text":"Quickstart Below is an example of a Short Range stream flow forecast for a stream segment on the Potomac River near DC. The comid representing this stream segment has been pulled from the NHDPlus V2.1 dataset. # Imports import gcsfs from fcast import Assim, ShortRange, plotShortRange %matplotlib inline # Connect gcsfs to the National Water Model fs = gcsfs.GCSFileSystem(project='national-water-model') # Parameters date = '20190802' # a date start_hr = '00' # start at 00:00 comid = 4512772 # stream segment on the Potomac near DC # Create a Short Range forecast and plot it ## Use the Assim class to get the Short Range forecast initial time/flow sim = Assim(fs, comid, date, start_hr) sr = ShortRange(fs, comid, date, start_hr) sr_df = sr.get_streamflow(sim.assim_time, sim.assim_flow) plotShortRange(sr_df, comid)","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"Below is an example of a Short Range stream flow forecast for a stream segment on the Potomac River near DC. The comid representing this stream segment has been pulled from the NHDPlus V2.1 dataset. # Imports import gcsfs from fcast import Assim, ShortRange, plotShortRange %matplotlib inline # Connect gcsfs to the National Water Model fs = gcsfs.GCSFileSystem(project='national-water-model') # Parameters date = '20190802' # a date start_hr = '00' # start at 00:00 comid = 4512772 # stream segment on the Potomac near DC # Create a Short Range forecast and plot it ## Use the Assim class to get the Short Range forecast initial time/flow sim = Assim(fs, comid, date, start_hr) sr = ShortRange(fs, comid, date, start_hr) sr_df = sr.get_streamflow(sim.assim_time, sim.assim_flow) plotShortRange(sr_df, comid)","title":"Quickstart"},{"location":"setup/","text":"Installation Linux / Mac You can install fcast by running: pip install fcast Windows To install fcast in a Windows environment, shapely , fiona , and gdal must first be installed manually from wheel files. The wheel files should be downloaded from Christoph Gohlke's Unofficial Windows Binaries for Python Extension Packages website . These wheels can be downloaded then installed using pip install <PATH TO WHEEL> . The wheels should match the python version of the environment and Windows bit version (32 or 64), which can be deduced and verified from the name of the downloaded wheel file. Once shapely , fiona , and gdal are installed from the wheel files, fcast can be installed by running: pip install fcast","title":"Setup"},{"location":"setup/#installation","text":"","title":"Installation"},{"location":"setup/#linux-mac","text":"You can install fcast by running: pip install fcast","title":"Linux / Mac"},{"location":"setup/#windows","text":"To install fcast in a Windows environment, shapely , fiona , and gdal must first be installed manually from wheel files. The wheel files should be downloaded from Christoph Gohlke's Unofficial Windows Binaries for Python Extension Packages website . These wheels can be downloaded then installed using pip install <PATH TO WHEEL> . The wheels should match the python version of the environment and Windows bit version (32 or 64), which can be deduced and verified from the name of the downloaded wheel file. Once shapely , fiona , and gdal are installed from the wheel files, fcast can be installed by running: pip install fcast","title":"Windows"}]}